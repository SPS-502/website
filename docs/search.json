[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SPS 502 | Data Science",
    "section": "",
    "text": "Instructor\n\n   Dr. Chris Birdsall\n   Environmental Research Building 1149\n   chrisbirdsall@boisestate.edu\n\n\n\nCourse details\n\n   Thursdays\n   August 25–December 15, 2022\n   6:00-8:45 p.m.\n   Bronco Gymnasium 218\n   Slack\n\n\n\nContacting me\nE-mail and the course Slack group are the best ways to get in contact with me. I will try to respond to all messages within 24 hours"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "labs/Lab01.html",
    "href": "labs/Lab01.html",
    "title": "SPS 502 | Data Science",
    "section": "",
    "text": "The main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\nAn additional goal is to introduce you to git and GitHub, which is the collaboration and version control system that we will be using throughout the course. Github is extremely helpful for tracking down problems with your code and for managing collaboration, which we’ll do in some labs later in the semester.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands."
  },
  {
    "objectID": "labs/Lab01.html#project-name",
    "href": "labs/Lab01.html#project-name",
    "title": "SPS 502 | Data Science",
    "section": "Project name:",
    "text": "Project name:\nCurrently your project is called Untitled Project. Update the name of your project to be “Lab 01 - Hello R”.\n\n\n\n\n\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for \"YAML Ain't Markup Language\". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document."
  },
  {
    "objectID": "labs/Lab01.html#yaml",
    "href": "labs/Lab01.html#yaml",
    "title": "SPS 502 | Data Science",
    "section": "YAML:",
    "text": "YAML:\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document."
  },
  {
    "objectID": "labs/Lab01.html#commiting-changes",
    "href": "labs/Lab01.html#commiting-changes",
    "title": "SPS 502 | Data Science",
    "section": "Commiting changes:",
    "text": "Commiting changes:\nThen Go to the Git pane in your RStudio.\nIf you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state that includes your changes. If you’re happy with these changes, write “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions."
  },
  {
    "objectID": "labs/Lab01.html#pushing-changes",
    "href": "labs/Lab01.html#pushing-changes",
    "title": "SPS 502 | Data Science",
    "section": "Pushing changes:",
    "text": "Pushing changes:\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only).\nIn order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me… We will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it."
  },
  {
    "objectID": "labs/Lab01.html#thought-exercise",
    "href": "labs/Lab01.html#thought-exercise",
    "title": "SPS 502 | Data Science",
    "section": "Thought exercise:",
    "text": "Thought exercise:\nFor which of the above steps (changing project name, making updates to the document, committing, and pushing changes) do you need to have an internet connection? Discuss with your classmates."
  },
  {
    "objectID": "labs/Lab01.html#open-the-starter-project-in-rstudio-cloud",
    "href": "labs/Lab01.html#open-the-starter-project-in-rstudio-cloud",
    "title": "SPS 502 | Data Science",
    "section": "Open the starter project in RStudio Cloud",
    "text": "Open the starter project in RStudio Cloud\nVisit RStudio.cloud and login using the credentials you setup in our first class. Once you load up RStudio Cloud in your web browser you should see something like this:\n\nIn the left side bar you’ll see a header, “Space”, under which you’ll see “Your Workspace” and “SPS 502-F22”. Click SPS 502-F22 to view the list of projects associated with our class.\nThere you’ll see the Lab 01 starter project, called “Lab 01 - Hello R!”.\nClick “Start” to begin the lab"
  },
  {
    "objectID": "labs/Lab01.html#opening-the-starter-file",
    "href": "labs/Lab01.html#opening-the-starter-file",
    "title": "SPS 502 | Data Science",
    "section": "Opening the starter file",
    "text": "Opening the starter file\nWhen you want to write a paper, you have to open a Word document to type your ideas into, and save your work in. In R we use a document type called an R Markdown document. R Markdown documents are useful for both running code, and annotating the code with comments. The document can be saved, so you can refer back to your code later, and can be used to create other document types (html, word, pdf, or slides) for presenting the results of your analyses. R Markdown provides a way to generate clear and reproducible statistical analyses."
  },
  {
    "objectID": "labs/Lab01.html#editing-an-r-markdown-file",
    "href": "labs/Lab01.html#editing-an-r-markdown-file",
    "title": "SPS 502 | Data Science",
    "section": "Editing an R Markdown file",
    "text": "Editing an R Markdown file\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML it contains meta information about your document, such as the title of the document, the author name, and the date.\nLet’s start by adding your first and last name in author field and adding the date. Be sure to keep the quotation marks."
  },
  {
    "objectID": "labs/Lab01.html#saving-a-file",
    "href": "labs/Lab01.html#saving-a-file",
    "title": "SPS 502 | Data Science",
    "section": "Saving a file",
    "text": "Saving a file\nYou will complete your lab work in an R Markdown file like this each week, so it is important to learn how to save these files. It’s generally good practice to periodically save your work as you go.\nClick File > Save\nOkay, let’s get to the fun part!"
  },
  {
    "objectID": "labs/Lab01.html#loading-packages",
    "href": "labs/Lab01.html#loading-packages",
    "title": "SPS 502 | Data Science",
    "section": "Loading Packages",
    "text": "Loading Packages\nIn this lab we will use the tidyverse and datasauRus packages. We can load them using the following (this code is already provided for you in your starter document):\n\nlibrary(tidyverse)\n\nlibrary(datasauRus)"
  },
  {
    "objectID": "labs/Lab01.html#data",
    "href": "labs/Lab01.html#data",
    "title": "SPS 502 | Data Science",
    "section": "Data",
    "text": "Data\nThe data frame we will be working with today is called datasaurus_dozen and it’s in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be run in the Console.\n\nBased on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report.\n\nLet’s take a closer look at these datasets by making a frequency table of the dataset variable. Add the following code block to your R Markdown document and run it (copy the code then paste it under your answer in exercise 1):\n\ndatasaurus_dozen %>%\ncount(dataset) %>%\nprint(13)\n\nYou should see a “tibble” pop up listing the names of the datasets in one column and the number of observations (n) in the next column."
  },
  {
    "objectID": "labs/Lab01.html#data-visualization-and-summary",
    "href": "labs/Lab01.html#data-visualization-and-summary",
    "title": "SPS 502 | Data Science",
    "section": "Data Visualization and Summary",
    "text": "Data Visualization and Summary\nOkay, we’re about to do a lot of stuff that won’t make a ton of sense yet. We’ll go through a brief explanation in this lab, but more details and context for these commands will come in the next couple of weeks. For now, buckle up!\n\nPlot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset. (Er… excuse me?)\n\nDon’t worry. All the code you need to accomplish this is already in your lab for you. You’ll just need to include the code and some other information in your R Markdown file.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data <- datasaurus_dozen %>%\n\nfilter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s go through each part:\nFirst, the pipe operator: %>%, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: <-, assigns the name dino_data to the filtered data frame and stores it as an object in your environment (take a look at the environment pane in the top left corner).\nNext, we need to visualize these data (yes, plural). We will use the ggplot function for this. The first argument specifies the data you’re visualizing. Next we define the aesthetic mappings (more on this next week). In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n\ngeom_point()\n\nIf this seems like a lot, it is. And you will learn about the philosophy of building data visualizations in detail next week. For now, just stick with it and follow along with the code . Again, I do not expect this to make much sense yet.\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficients, often referred to as \\(r\\) in statistics, measure the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear…. it’s shaped like a dinosaur!\nBut, for illustrative purposes, let’s calculate the correlation coefficient between x and y anyway.\n\n\nStart with dino_data and calculate a summary statistic that we will call r as the correlation between x and y.\n\ndino_data %>%\n  summarize(r = cor(x, y))\n\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\nPlot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\nFinally, let’s plot all datasets at once. In order to do this we will make use of facetting.\n\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+\n  geom_point()+\n  facet_wrap(~ dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\nFacet by the dataset variable, placing the plots in a 3 column grid, and don’t add a legend.\nAnd we can use the group_by function to generate all the summary correlation coefficients.\n\ndatasaurus_dozen %>%\n  group_by(dataset) %>%\n  summarize(r = cor(x, y)) %>%\n  print(13)"
  },
  {
    "objectID": "labs/Lab01.html#knitting-an-html-file",
    "href": "labs/Lab01.html#knitting-an-html-file",
    "title": "SPS 502 | Data Science",
    "section": "Knitting an HTML file",
    "text": "Knitting an HTML file\nClick the Knit button at the top left side of the screen to “knit” the file, or in other words, produce an output document. An .html file will be generated.\nNote: If you see the popup below you can just hit cancel:\n\nThen click on the html file in the “Files” pane to open it in your web browser:"
  },
  {
    "objectID": "labs/Lab01.html#finishing-touches",
    "href": "labs/Lab01.html#finishing-touches",
    "title": "SPS 502 | Data Science",
    "section": "Finishing touches",
    "text": "Finishing touches\nAlmost done, but I’d like you to do two more things:\n\nResize your figures:\n\nClick on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the pop up dialogue box go to the Figures tab and change the height and width of the figures, and hit OK when done. Then, knit your document and see how you like the new sizes. Change and knit again and again until you’re happy with the figure sizes. Note that these values get saved in the YAML.\n\nYou can also use different figure sizes for different figures. To do so click on the gear icon within the chunk where you want to make a change. Changing the figure sizes added new options to these chunks: fig.width and fig.height. You can change them by defining different values directly in your R Markdown document as well.\n\n\nChange the look of your report:\n\nOnce again click on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the General tab of the pop up dialogue box try out different Syntax highlighting and theme options. Hit OK and knit your document to see how it looks. Play around with these until you’re happy with the look."
  },
  {
    "objectID": "labs/Lab01.html#submission",
    "href": "labs/Lab01.html#submission",
    "title": "SPS 502 | Data Science",
    "section": "Submission",
    "text": "Submission\nFinally, you need to save your html file and submit it to me on Canvas. Here’s how to do it (see image below for reference):\n\n\nFirst, click the checkbox next to the html file in your files pane.\nNext, click “More” and select “Export”\nSave the html file somewhere on your computer where you can find it (e.g., downloads folder, documents folder, desktop, or a folder you created for the class).\nGo to our class page on canvas and click on “assignments”. Navigate to “Lab 01” under “Labs” and submit just as you would a paper in any other class.\n\nAnd you’re done!"
  },
  {
    "objectID": "labs/Lab02.html#packages",
    "href": "labs/Lab02.html#packages",
    "title": "SPS 502 | Data Science",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for this analysis. Run the following code to load this package.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/Lab02.html#data",
    "href": "labs/Lab02.html#data",
    "title": "SPS 502 | Data Science",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file in the data folder in the files pane. You can read it in using the following:\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "labs/Lab02.html#submission",
    "href": "labs/Lab02.html#submission",
    "title": "SPS 502 | Data Science",
    "section": "Submission",
    "text": "Submission\nFinally, you need to save your html file and submit it to me on Canvas. Here’s how to do it (see image below for reference):\n\n\nFirst, click the checkbox next to the html file in your files pane.\nNext, click “More” and select “Export”\nSave the html file somewhere on your computer where you can find it (e.g., downloads folder, documents folder, desktop, or a folder you created for the class).\nGo to our class page on canvas and click on “assignments”. Navigate to “Lab 01” under “Labs” and submit just as you would a paper in any other class.\n\nAnd you’re done!"
  },
  {
    "objectID": "labs/Lab02.html#exercise-1",
    "href": "labs/Lab02.html#exercise-1",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 1",
    "text": "Exercise 1\nPlot, using histograms, the distribution of plastic waste per capita faceted by continent. What can you say about how the continents compare to each other in terms of their plastic waste per capita? Write and run the code required to create the faected histogram plot in your RMarkdown file.\n\n\nNOTE: Moving forward, the plots and the output of the code are not displayed in the lab instructions, but, as previously stated, you can and should copy the code to your R Markdown file and view the results yourself.\n\nDesnsity plots\nAnother way of visualizing numerical data is using density plots.\n\nggplot(data = plastic_waste, aes(x = plastic_waste_per_cap)) +\n  geom_density()\n\nAnd compare distributions across continents by coloring density curves by continent.\n\nggplot(data = plastic_waste, \n       mapping = aes(x = plastic_waste_per_cap, \n                     color = continent)) +\n  geom_density()\n\nThe resulting plot may be a little difficult to read, so let’s also fill the curves in with colors as well.\n\nggplot(data = plastic_waste, \n       mapping = aes(x = plastic_waste_per_cap, \n                     color = continent, \n                     fill = continent)) +\n  geom_density()\n\nThe overlapping colors make it difficult to tell what’s happening with the distributions in continents plotted first, and hence covered by continents plotted over them. We can change the transparency level of the fill color to help with this. The alpha argument takes values between 0 and 1 (e.g., 0.5): 0 is completely transparent and 1 is completely opaque. There is no way to tell what value will work best, so you just need to try a few.\n\nggplot(data = plastic_waste, \n       mapping = aes(x = plastic_waste_per_cap, \n                     color = continent, \n                     fill = continent)) +\n  geom_density(alpha = 0.7)\n\nThis still doesn’t look great…"
  },
  {
    "objectID": "labs/Lab02.html#exercise-2",
    "href": "labs/Lab02.html#exercise-2",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 2",
    "text": "Exercise 2\nRecreate the density plots above using a different (lower) alpha level that works better for displaying the density curves for all continents."
  },
  {
    "objectID": "labs/Lab02.html#exercise-3",
    "href": "labs/Lab02.html#exercise-3",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhy do we define the color and fill of the curves by mapping aesthetics of the plot, but define the alpha level as a characteristic of the plotting geom?\n\n\nHint: you may need to go back and read about the alpha argument in ModernDive to answer this question.\nAnd yet another way to visualize this relationship is using side-by-side box plots.\n\nggplot(data = plastic_waste, \n       mapping = aes(x = continent, \n                     y = plastic_waste_per_cap)) +\n  geom_boxplot()"
  },
  {
    "objectID": "labs/Lab02.html#exercise-4",
    "href": "labs/Lab02.html#exercise-4",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 4",
    "text": "Exercise 4\nConvert your side-by-side box plots from the previous task to violin plots. What do the violin plots reveal that box plots do not? What features are apparent in the box plots but not in the violin plots?"
  },
  {
    "objectID": "labs/Lab02.html#exercise-5",
    "href": "labs/Lab02.html#exercise-5",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 5",
    "text": "Exercise 5\nVisualize the relationship between plastic waste per capita and mismanaged plastic waste per capita using a scatterplot. Describe the relationship.\n\n\nRemember: We use geom_point() to make scatterplots."
  },
  {
    "objectID": "labs/Lab02.html#exercise-6",
    "href": "labs/Lab02.html#exercise-6",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 6",
    "text": "Exercise 6\nColor the points in the scatterplot by continent. Does there seem to be any clear distinctions between continents with respect to how plastic waste per capita and mismanaged plastic waste per capita are associated?"
  },
  {
    "objectID": "labs/Lab02.html#exercise-7",
    "href": "labs/Lab02.html#exercise-7",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 7",
    "text": "Exercise 7\nVisualize the relationship between plastic waste per capita and total population as well as plastic waste per capita and coastal population. You will need to make two separate plots. Do either of these pairs of variables appear to be more strongly linearly associated?"
  },
  {
    "objectID": "hw/hw01.html#logistics-and-tips-for-success",
    "href": "hw/hw01.html#logistics-and-tips-for-success",
    "title": "SPS 502 | Data Science",
    "section": "Logistics and tips for success",
    "text": "Logistics and tips for success\nThis lab will require you to write some of your own code (similar to lab 2). Read these instructions carefully as you work through the homework assignment.\n\nHow to answer questions\nSome questions will direct you to write code, while others will direct you to write a response. You’ll see TYPE YOUR ANSWER HERE in your RMarkdown file in places where I expect you to write a response. And you’ll see code blocks with #Delete and enter your code where I expect you to write your own code.\n\n\nCopying/pasting and writing code\nCopying and editing code from other answers or examples is a great way to both save time and learn. If you copy code over and something isn’t working, look carefully at the edits you made to see whether you missed something in the copying/pasting process. Also, be sure you’ve edited ALL the variable/object names appropriately so you’re accomplishing what the question is asking you to do. You should also make sure that you’re typing the variable and object names EXACTLY as they appear in the dataset or environment pane (spelling and case must match exactly).\n\n\nIf you’re stuck\nIf you get stuck, don’t panic! Before you ask for help, give yourself a few minutes to figure it out. Search ModernDive, look at your previous labs, and google your problem with “tidyverse”. Also, step away from your computer for a few minutes if you need a break. Finally (and this doesn’t have to be the last step), ask for help on Slack!"
  },
  {
    "objectID": "hw/hw01.html#load-packages",
    "href": "hw/hw01.html#load-packages",
    "title": "SPS 502 | Data Science",
    "section": "Load Packages",
    "text": "Load Packages\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw01.html#import-data",
    "href": "hw/hw01.html#import-data",
    "title": "SPS 502 | Data Science",
    "section": "Import Data",
    "text": "Import Data\nNext, let’s load the data:\n\n# Load raw data\nidaho_crashes_raw <- read_csv(\"data/Crash_Data_2005__Present.csv\")\n\nRows: 299135 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Severity, County, IntersectionRelated\ndbl  (5): OBJECTID, Mile_Point, Accident_Year, Number_Of_Fatalities, Number_...\ndttm (1): Accident_Date_Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhat do the data look like? Here are a few ways to view data in r\n\nidaho_crashes_raw\n\n\nglimpse(idaho_crashes_raw)\n\n\nstr(idaho_crashes_raw)\n\nRun the already provided code in your Rmarkdown file to get a sense of the dataset. More detail about these commands is available in ModernDive."
  },
  {
    "objectID": "hw/hw01.html#data-overview",
    "href": "hw/hw01.html#data-overview",
    "title": "SPS 502 | Data Science",
    "section": "Data Overview",
    "text": "Data Overview\n\nQuestion 1\n\nWhat is another method you’ve used/learned to View a dataset? (HINT: The command is in the question). Type the code in the code block under “Question 1” in your RMarkdown file in RStudio Cloud. If you have no idea go back to ModernDive Chapter 1 (sec 1.4.3).\n\n\n\nQuestion 2\n\nWhat have we learned about the data? How many car accidents (observations/rows) do we have? How many variables (columns)? Type your answers in your RMarkdown sheet."
  },
  {
    "objectID": "hw/hw01.html#clean-the-data",
    "href": "hw/hw01.html#clean-the-data",
    "title": "SPS 502 | Data Science",
    "section": "Clean the data",
    "text": "Clean the data\nOkay, let’s clean up the raw data a little and get some useful information along the way. First, we’ll use the lubridate package to get useful information from the Accident_Date_Time variable, as well as rename a variable to make it easier to remember (we’ll cover more about the lubridate package in the future).\n\nidaho_crashes_clean <- idaho_crashes_raw %>% \n  mutate(Hour= hour(Accident_Date_Time),\n         Month = month(Accident_Date_Time, label = TRUE, abbr = TRUE),\n         Day = wday(Accident_Date_Time, label = TRUE, abbr = TRUE)) %>%\n    rename(Year = Accident_Year)\n\nThe lubridate package allowed us to extract useful information from the Accident_Date_Time variable.\nRun the code below to learn more about the lubridate package:\n\n?lubridate\n\nNow we have a “cleaned” version of the data stored in a dataframe called ‘idaho_crashes_clean’.\nLet’s take another look at the data:\n\nidaho_crashes_clean\n\n\nQuestion 3\n\nWhat’s new in this dataset (idaho_crashes_clean) compared to the raw version? Write your answer in your RMarkdown sheet."
  },
  {
    "objectID": "hw/hw01.html#accidents-over-time",
    "href": "hw/hw01.html#accidents-over-time",
    "title": "SPS 502 | Data Science",
    "section": "Accidents over time",
    "text": "Accidents over time\nNow that we have our data in shape, let’s see if we can gain any insights about car accidents in Idaho.\n\nQuestion 4\n4a. First, has the number of accidents increased since 2005?\nThings to try:\nCreate a new dataframe that groups the number of accidents per year:\n\naccidents_per_year <- idaho_crashes_clean %>% \n  count(Year)\n\n#Print the result \naccidents_per_year\n\n# A tibble: 13 × 2\n    Year     n\n   <dbl> <int>\n 1  2005 28137\n 2  2006 24156\n 3  2007 26452\n 4  2008 25069\n 5  2009 22625\n 6  2010 22170\n 7  2011 20600\n 8  2012 11459\n 9  2013 21387\n10  2014 22279\n11  2015 23904\n12  2016 25181\n13  2017 25716\n\n\nTry adding , sort = TRUE in count() in the code above and run the command again in another code block. Copy the code and paste it into the code block provided in your RMarkdown file. Then edit the code accordingly and run it again.\n4b. Why would you want to sort this list? Why would you not want to sort this list? Write your answer in your RMarkdown file.\n\n\nQuestion 5\nNext, let’s try a visualization:\n\nggplot(data = accidents_per_year, \n       mapping = aes(x = Year, y = n)) +\n      labs(y = \"Car Crashes\",\n           x = \"Year\") +\n  scale_x_continuous(breaks = pretty_breaks())+\n  geom_line()\n\n\n\n\n\nNotice anything strange? What’s going on in 2012? Which did you find more informative, the tibble (table with the count of accidents) or the visualization? Write your answer in your RMarkdown file."
  },
  {
    "objectID": "hw/hw01.html#accidents-by-month",
    "href": "hw/hw01.html#accidents-by-month",
    "title": "SPS 502 | Data Science",
    "section": "Accidents by month",
    "text": "Accidents by month\n\nQuestion 6\n\nWhich is the most dangerous month? Let’s create a new dataframe that groups accidents by month then create a line graph to visualize the data. Try writing the code yourself this time. (HINT: the code is nearly identical to the three codeblocks above)."
  },
  {
    "objectID": "hw/hw01.html#accidents-by-time-of-day",
    "href": "hw/hw01.html#accidents-by-time-of-day",
    "title": "SPS 502 | Data Science",
    "section": "Accidents by time of day",
    "text": "Accidents by time of day\nLet’s see what the worst time of day is for accidents.\nWe have the hour of the crash recorded in the variable Hour, which lists the hour from 0 to 23.\n\nidaho_crashes_clean %>% \n  count(Hour, sort = TRUE)\n\n# A tibble: 24 × 2\n    Hour     n\n   <int> <int>\n 1    17 25822\n 2    16 24816\n 3    15 24368\n 4    12 19454\n 5    14 19305\n 6    18 18277\n 7    13 18230\n 8    11 15617\n 9     7 15519\n10     8 14967\n# … with 14 more rows\n\n\n\nQuestion 7\n\nWhich are the top 3 worst hours for car accidents? What time of day is this? Type your answer in the RMarkdown file."
  },
  {
    "objectID": "hw/hw01.html#accidents-by-county",
    "href": "hw/hw01.html#accidents-by-county",
    "title": "SPS 502 | Data Science",
    "section": "Accidents by county",
    "text": "Accidents by county\n\nQuestion 8\n8a. Which is the most dangerous county? Run the code below to find out!\n\naccidents_by_county <- idaho_crashes_clean %>%\n  count(County, sort = TRUE)\n\n#Print the result\naccidents_by_county\n\n8b. Are you surprised? Why or why not?\n8c. This may not be the best measure to determine which is the most dangerous county. Why? What might be a better measure? Do we need additional data?"
  },
  {
    "objectID": "hw/hw01.html#fatal-accidents",
    "href": "hw/hw01.html#fatal-accidents",
    "title": "SPS 502 | Data Science",
    "section": "Fatal Accidents",
    "text": "Fatal Accidents\nThe dataset has information on whether accidents are fatal recorded in the variable, Number_Of_Fatalities. Let’s focus on those and see if the trends are any different.\nThere are a number of ways to do this, but let’s keep it simple for now and use the subset function to create a new dataframe which only includes fatal accidents (i.e. observations where number of fatalities is greater than zero).\n\nidaho_fatal_crashes <- subset(idaho_crashes_clean, subset = Number_Of_Fatalities > 0)\n\n#Print the result\nidaho_fatal_crashes\n\nAlright. A much smaller dataset. Let’s dig in a bit.\n\nQuestion 9\nFirst, let’s see if the most dangerous counties are also the deadliest. You’ll need to write this code yourself.\n9a. Create a new dataframe that counts the number of fatal crashes per county and print the result.\n9b. Next, create a visualization showing fatal crashes by county. Enter your code in the codeblocks provided in the RMarkdown file.\n9c. What are the similarities and differences between this and the original county list? Type your answer in the RMarkdown file.\n\n\nHint: The code will be very, very similar to the code in Question 8 (in codeblock count-county) and the code in Question 5 (in codeblock count-year-viz). You will just need to figure out which inputs to replace so that you’re using the right data.\n\n\nQuestion 10\nNow let’s look at fatal accidents by month.\n10a. Create a new dataframe counting fatal accidents by month.\n10b. Next, create a linegraph to visualize the data.\nBased on your tables and visualizations, how do fatal accidents by month differ from total accidents by month? What might explain the differences? Provide your code and your written answer in your RMarkdown file."
  },
  {
    "objectID": "hw/hw01.html",
    "href": "hw/hw01.html",
    "title": "SPS 502 | Data Science",
    "section": "",
    "text": "Due by 11:59 p.m., Friday September 16"
  },
  {
    "objectID": "hw/hw01.html#exploring-the-data",
    "href": "hw/hw01.html#exploring-the-data",
    "title": "SPS 502 | Data Science",
    "section": "Exploring the Data",
    "text": "Exploring the Data\n\nQuestion 1\n\nWhat is another method you’ve used/learned to View a dataset? (HINT: The command is in the question). Type the code in the code block under “Question 1” in your RMarkdown file in RStudio Cloud.\n\n\n\nQuestion 2\n\nWhat have we learned about the data? How many car accidents (observations/rows) do we have? How many variables (columns)? Type your answers in your RMarkdown sheet."
  },
  {
    "objectID": "labs/Lab03.html#packages",
    "href": "labs/Lab03.html#packages",
    "title": "SPS 502 | Data Science",
    "section": "Packages",
    "text": "Packages\nRun the following to load the necessary packages for this lab:\n\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "labs/Lab03.html#data",
    "href": "labs/Lab03.html#data",
    "title": "SPS 502 | Data Science",
    "section": "Data",
    "text": "Data\nRun the following to load and take a glimpse of the data:\n\ndata(txhousing)\nglimpse(txhousing)\n\nThese data are about housing in Texas. Each row is monthly data for a given city in Texas in a given year. There are multiple years of data for each city."
  },
  {
    "objectID": "labs/Lab03.html#exercise-1",
    "href": "labs/Lab03.html#exercise-1",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 1",
    "text": "Exercise 1\nTake a look at the data in the data viewer. You can accomplish this two different ways: A) click on the name of the data in the Environment pane, or b) type View(txhousing) in the console. What is the last city listed in the data set (in row 8602)?\n\n\nIn homework 1 we learned (and I was reminded) that RStudio does not like to knit documents that execute the View() command. So from now on, we’ll just run it in the console to avoid additional headaches."
  },
  {
    "objectID": "labs/Lab03.html#exercise-2",
    "href": "labs/Lab03.html#exercise-2",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 2",
    "text": "Exercise 2\nTake a look at the variable descriptions by typing ?txhousing into the console. What is the listings variable in this data set?"
  },
  {
    "objectID": "labs/Lab03.html#select",
    "href": "labs/Lab03.html#select",
    "title": "SPS 502 | Data Science",
    "section": "select",
    "text": "select\nSometimes we want to pull out or extract just one or two columns of data. The following code will extract only the column in the data set for the variables sales and volume.\n\ntxhousing %>% select(sales, volume)\n\nThe %>% symbol is called the piping operator. Here, it takes the txhousing data frame and “pipes” or feeds it into the select function. You can think of the %>% symbol as the word “then”.\nNote that we did not use an assignment operator <- so we did not save these extracted, selected values. In the following code, we save the results, in a data frame ASLO called txhousing. By putting - in front of the date variable we tell R to select all except the date variable. Run the following code:\n\ntxhousing <- txhousing %>% select(-date)\n\nIf you look at txhousing in the data viewer, the date variable is no longer included."
  },
  {
    "objectID": "labs/Lab03.html#filter",
    "href": "labs/Lab03.html#filter",
    "title": "SPS 502 | Data Science",
    "section": "filter",
    "text": "filter\nThe filter function allows you to pull out just the rows (cases or observations) you want, based on some criteria in one of the columns.\nImagine for instance that we wanted to reduce the data set include data for only 2012, in Austin. This code chunk takes the txhousing data, then filters it to only include rows in which the year is 2012, and the city is Austin. The results are saved in a new data frame called austin_12 that shows up in the workspace.\n\naustin_12 <- txhousing %>% filter(year == 2012, city == \"Austin\")\n\n\nNote that we use == to identify the desired criteria.\n\nWhat if we wanted to restrict our data set to only years before 2004 and the City of Austin? Below we use the < symbol to accomplish this. Note we did not SAVE these results in a new data frame…so no new data frame showed up in our Environment pane, but the results print out immediately below the code chunk.\n\ntxhousing %>% filter(year < 2004, city == \"Austin\")\n\nWhat if we wanted to use multiple cities? Below we use the | symbol to indicate that the city could be Austin OR Abilene. In this case, we saved these results as a new data frame called aust_ab that appears in your Environment pane.\n\naust_ab <- txhousing %>% filter(city == \"Austin\" | city == \"Abilene\")"
  },
  {
    "objectID": "labs/Lab03.html#mutate",
    "href": "labs/Lab03.html#mutate",
    "title": "SPS 502 | Data Science",
    "section": "mutate",
    "text": "mutate\nThe mutate function can add new columns (variables) to a data frame. For instance, the following will add a new column to the data called vol_100k that expresses volume in units of $100000.\n\ntxhousing <- txhousing %>%\n  mutate(vol_100k = volume/100000)\n\nNote that we SAVED these results in new data frame called txhousing. This therefore overwrote the old txhousing data frame with a new version that contains this column. You can open the txhousing data frame in the viewer to confirm that it now contains this new column."
  },
  {
    "objectID": "labs/Lab03.html#summarize",
    "href": "labs/Lab03.html#summarize",
    "title": "SPS 502 | Data Science",
    "section": "summarize",
    "text": "summarize\nOne of the first tasks in data analysis is often to get descriptive statistics that help to understand the central tendency and variability in the data. The summarize() command can take a column of data, and reduce it to a summary statistic.\nFor instance, the code below uses the austin_12 data set made earlier to calculate the mean monthly number of sales in Austin in 2012.\n\naustin_12 %>% summarize(x_bar_sales = mean(sales))\n\nThis code tells R to calculate the mean of the variable sales, and to save the results in a variable called x_bar_sales.\nYou can also calculate multiple summary statistics at once, and even for multiple variables. Below we also calculate a standard deviation sd() of sales, a minimum min() of the volume variable, a maximum max() of the volume variable, etc. The n() calculates sample size…or the number of rows/ cases in the data frame.\n\naustin_12 %>% summarize(x_bar_sales = mean(sales), \n                        sd_sales = sd(sales), \n                        min_vol = min(volume), \n                        max_vol = max(volume), \n                        mdn_list = median(listings), \n                        iqr_list = IQR(listings),\n                        sample_size = n())\n\n# A tibble: 1 × 7\n  x_bar_sales sd_sales   min_vol   max_vol mdn_list iqr_list sample_size\n        <dbl>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>       <int>\n1       2127.     501. 265821275 791281075     7925     949.          12\n\n\nNote that the names of the elements you calculate are user defined, like xbar_sales, min_vol, and mdn_list. You could customize these names as you like (but don’t use spaces in your names)."
  },
  {
    "objectID": "labs/Lab03.html#arrange",
    "href": "labs/Lab03.html#arrange",
    "title": "SPS 502 | Data Science",
    "section": "arrange",
    "text": "arrange\nYou just determined that the maximum volume of monthly sales in Austin in 2012 was a total of $791,281,075 ….but what if you wanted to know WHAT MONTH that occurred in? Copy paste, and run the following into a new code chunk:\n\naustin_12 %>%\n  arrange(desc(volume))\n\nThis tells R to arrange the rows in the data set based on the volume column, and to do so in descending order. So the row with the $791,281,075 in sales is shown at the top! We can see that this volume occurred in the sixth month (June)."
  },
  {
    "objectID": "labs/Lab03.html#group_by",
    "href": "labs/Lab03.html#group_by",
    "title": "SPS 502 | Data Science",
    "section": "group_by",
    "text": "group_by\nSometimes we also want to calculate summary statistics across different levels of another variable. For instance, here we find the average number of monthly sales that occurred in Abilene and Austin across all years in the data set. Note that we use the aust_ab data frame we created earlier, to restrict our analysis to those two cities.\n\naust_ab %>% group_by(city) %>% \n  summarize(x_bar_sales = mean(sales))\n\n# A tibble: 2 × 2\n  city    x_bar_sales\n  <chr>         <dbl>\n1 Abilene        150.\n2 Austin        1997.\n\n\nFrom the results we can see that there were an average of 150 sales per month in Abilene, and 1996 in Austin.\nWe can give R multiple variables to group by. For instance, this code gives us the mean sales for each month in each city, averaged across all the years. So for instance the mean number of sales in January, in Abilene was 96 homes.\n\naust_ab %>% group_by(city, month) %>% \n  summarize(x_bar_sales = mean(sales))"
  },
  {
    "objectID": "labs/Lab03.html#exercise-3",
    "href": "labs/Lab03.html#exercise-3",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 3",
    "text": "Exercise 3\nWrite a code chunk to remove the inventory variable. Save the results in a data frame called txhousing. Confirm in the data viewer that the variable has been removed."
  },
  {
    "objectID": "labs/Lab03.html#exercise-4",
    "href": "labs/Lab03.html#exercise-4",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 4",
    "text": "Exercise 4\nMake a data set called dallas_sub that includes data only from the city of Dallas in 2012 & 2013."
  },
  {
    "objectID": "labs/Lab03.html#exercise-5",
    "href": "labs/Lab03.html#exercise-5",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 5",
    "text": "Exercise 5\nAdd a column to the dallas_sub data set called prct_sold that calculates the percentage of listings that were sold (sales/listings * 100). Be sure to save the results also as a data frame called dallas_sub."
  },
  {
    "objectID": "labs/Lab03.html#exercise-6",
    "href": "labs/Lab03.html#exercise-6",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 6",
    "text": "Exercise 6\nCalculate the average percentage of listings that were sold in Dallas in each month of the year based on your dallas_sub data set. Save the results of the calculation in an data frame called dallas_summary."
  },
  {
    "objectID": "labs/Lab03.html#exercise-7",
    "href": "labs/Lab03.html#exercise-7",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 7",
    "text": "Exercise 7\nArrange the dallas_summary in descending order based on the average percentage of listings, so you can see which month had the greatest average percentage of listings sold. You do not need to save the results."
  },
  {
    "objectID": "labs/Lab03.html#advanced-wrangling-exercises",
    "href": "labs/Lab03.html#advanced-wrangling-exercises",
    "title": "SPS 502 | Data Science",
    "section": "Advanced Wrangling Exercises",
    "text": "Advanced Wrangling Exercises\nYou may have to use multiple dplyr functions to answer each question. Think through the steps of how to get to the answer you are trying to find."
  },
  {
    "objectID": "labs/Lab03.html#exercise-8",
    "href": "labs/Lab03.html#exercise-8",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 8",
    "text": "Exercise 8\nRun the following code chunk. Study the code, and the output. Explain in your own words what this code chunk calculated.\n\ntxhousing %>% \n  filter(year == 2012 | year == 2013, city == \"Dallas\") %>%\n  mutate(prct_sold = sales/listings *100) %>%\n  group_by(month) %>%\n  summarize(mean_prct_sold = mean(prct_sold)) %>% \n  arrange(desc(mean_prct_sold))"
  },
  {
    "objectID": "labs/Lab03.html#exercise-9",
    "href": "labs/Lab03.html#exercise-9",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 9",
    "text": "Exercise 9\nIn January of 2015, what city had the fewest houses listed for sale?"
  },
  {
    "objectID": "labs/Lab03.html#exercise-10",
    "href": "labs/Lab03.html#exercise-10",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 10",
    "text": "Exercise 10\nIn 2012, in which month were the most houses sold in Texas?"
  },
  {
    "objectID": "labs/Lab03.html#exercise-11",
    "href": "labs/Lab03.html#exercise-11",
    "title": "SPS 502 | Data Science",
    "section": "Exercise 11",
    "text": "Exercise 11\nGenerate a single table that shows the total number of houses sold in Austin in 2000 and 2001 (total over the entire period), and the total number of houses sold in Dallas in 2000 and 2001 (total over the entire period). This calculation requires a number of steps, so it might help you to first write out on paper the different steps you will need to take. That will help you set out a “blueprint” for tackling the problem.\n\n\nHint: recall the sum() function can add(+) values."
  },
  {
    "objectID": "labs/Lab03.html",
    "href": "labs/Lab03.html",
    "title": "SPS 502 | Data Science",
    "section": "",
    "text": "#Lab 03 - Data Wrangling"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#testing-this",
    "href": "lectures/lecture03/lecture03.html#testing-this",
    "title": "Data Wrangling",
    "section": "Testing this",
    "text": "Testing this\nTesting"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mean",
    "href": "lectures/lecture03/lecture03.html#mean",
    "title": "Data Wrangling",
    "section": "Mean",
    "text": "Mean\n\n\nArithmetic Mean (\\(\\bar{x}\\) or \\(\\mu\\)): the sum of a series of observations divided by the number of observations \\[\\bar{x} = \\frac{1}{n}\\left (\\sum_{i=1}^n{x_i}\\right ) = \\frac{x_1+x_2+\\cdots +x_n}{n}\\]\nUse when describing continuous variables\nSensitive to extreme values (e.g., income)"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#median",
    "href": "lectures/lecture03/lecture03.html#median",
    "title": "Data Wrangling",
    "section": "Median",
    "text": "Median\n\n\nThe middle value in a series of observations\n\nArrange a series of observations from smallest to greatest then take the middle value\n\nNote: if there is an even number of observations, then there is no single middle value; the median is then usually defined to be the mean of the two middle values\n\n\nIn a distribution, the median is the \\(2^{nd}\\) quartile and the \\(50^{th}\\) percentile\nUse when describing continuous variables\nRobust to extreme values (e.g., income)"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#normal-distribution",
    "href": "lectures/lecture03/lecture03.html#normal-distribution",
    "title": "Data Wrangling",
    "section": "Normal Distribution",
    "text": "Normal Distribution"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#central-tendency-normal-distribution",
    "href": "lectures/lecture03/lecture03.html#central-tendency-normal-distribution",
    "title": "Data Wrangling",
    "section": "Central Tendency (Normal Distribution)",
    "text": "Central Tendency (Normal Distribution)"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#skewed-distribution",
    "href": "lectures/lecture03/lecture03.html#skewed-distribution",
    "title": "Data Wrangling",
    "section": "Skewed Distribution",
    "text": "Skewed Distribution"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#postive-skewed-distribution",
    "href": "lectures/lecture03/lecture03.html#postive-skewed-distribution",
    "title": "Data Wrangling",
    "section": "Postive Skewed Distribution",
    "text": "Postive Skewed Distribution"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#negative-skewed-distribution",
    "href": "lectures/lecture03/lecture03.html#negative-skewed-distribution",
    "title": "Data Wrangling",
    "section": "Negative Skewed Distribution",
    "text": "Negative Skewed Distribution"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mode",
    "href": "lectures/lecture03/lecture03.html#mode",
    "title": "Data Wrangling",
    "section": "Mode",
    "text": "Mode\n\nMode: the most common value in a series of observations\n\nSome variables include multiple modes (multimodal)\n\nUse when describing discrete (e.g., categorical) variables"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#central-tendency-review",
    "href": "lectures/lecture03/lecture03.html#central-tendency-review",
    "title": "Data Wrangling",
    "section": "Central Tendency Review",
    "text": "Central Tendency Review\n\nArithmetic mean: sum of values divided by number of values\nMedian: middle value\nMode: most frequent value\nWhat is the mean, median, and mode of \\(x\\)?\n\n\\(x\\) = {1, 2, 2, 3, 4, 7, 9, 10, 11, 12, 12}"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#variance",
    "href": "lectures/lecture03/lecture03.html#variance",
    "title": "Data Wrangling",
    "section": "Variance",
    "text": "Variance\n\nVariance (\\(s^{2}\\), \\(\\sigma^{2}\\)): the extent to which a variable’s values deviate from or vary around it’s mean; the average distance of each observation from the mean \\[s^{2} = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\\]"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#variance-1",
    "href": "lectures/lecture03/lecture03.html#variance-1",
    "title": "Data Wrangling",
    "section": "Variance",
    "text": "Variance\n\nMeasures how far observations are from their average value (spread of the data)\n\nLow variance \\(\\rightarrow\\) observations are relatively close to the mean value\nHigh variance \\(\\rightarrow\\) observations are relatively far from the mean value\n\nExpressed in square units (i.e., \\(\\text{inches}^2\\))"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#dispersion-standard-deviation",
    "href": "lectures/lecture03/lecture03.html#dispersion-standard-deviation",
    "title": "Data Wrangling",
    "section": "Dispersion (Standard Deviation)",
    "text": "Dispersion (Standard Deviation)\n\nStandard Deviation (\\(s\\), \\(\\sigma\\)): standardized measure of variance \\[s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}\\]\nExpressed in the same units as the mean (i.e., inches)\n\nMean distance from the mean"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#standard-deviation",
    "href": "lectures/lecture03/lecture03.html#standard-deviation",
    "title": "Data Wrangling",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nStandard Deviation (\\(s\\), \\(\\sigma\\)): standardized measure of variance \\[s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}\\]\nExpressed in the same units as the mean (i.e., inches)\n\nMean distance from the mean"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#pipe",
    "href": "lectures/lecture03/lecture03.html#pipe",
    "title": "Data Wrangling",
    "section": "pipe %>%",
    "text": "pipe %>%\n\nleave_house(get_dressed(get_out_of_bed(wake_up(chris))))\n\n\n“Pipe” a data frame into a “verb” command\n“Chain” the results from one “verb” command into another\nThink of it as the word “then”\n\n\nWriting it out using pipes give it a more natural (and easier to read) structure\n\n\nchris %>% \n  wake_up() %>% \n  get_out_of_bed() %>% \n  get_dressed() %>% \n  leave_house()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#pipe-1",
    "href": "lectures/lecture03/lecture03.html#pipe-1",
    "title": "Data Wrangling",
    "section": "pipe %>%",
    "text": "pipe %>%\n\nleave_house(get_dressed(get_out_of_bed(wake_up(chris))))\n\n\n“Pipe” a data frame into a “verb” command\n“Chain” the results from one “verb” command into another\nThink of it as the word “then”\n\n\nchris %>% \n  wake_up() %>% \n  get_out_of_bed() %>% \n  get_dressed() %>% \n  leave_house()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#data-wrangling-1",
    "href": "lectures/lecture03/lecture03.html#data-wrangling-1",
    "title": "Data Wrangling",
    "section": "Data Wrangling",
    "text": "Data Wrangling"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#select",
    "href": "lectures/lecture03/lecture03.html#select",
    "title": "Data Wrangling",
    "section": "select()",
    "text": "select()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#select-1",
    "href": "lectures/lecture03/lecture03.html#select-1",
    "title": "Data Wrangling",
    "section": "select()",
    "text": "select()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#filter",
    "href": "lectures/lecture03/lecture03.html#filter",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#filter-1",
    "href": "lectures/lecture03/lecture03.html#filter-1",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#filter-2",
    "href": "lectures/lecture03/lecture03.html#filter-2",
    "title": "Data Wrangling",
    "section": "filter()",
    "text": "filter()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#summarize",
    "href": "lectures/lecture03/lecture03.html#summarize",
    "title": "Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\n\nSummary functions take many values and return one value meant to describe all those values as a group."
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#summarize-1",
    "href": "lectures/lecture03/lecture03.html#summarize-1",
    "title": "Data Wrangling",
    "section": "summarize()",
    "text": "summarize()\n\nidaho_crashes %>% \n  summarize(avg_injuries = mean(Number_Of_Injuries))\n\n# A tibble: 1 × 1\n  avg_injuries\n         <dbl>\n1        0.521"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#group_by-summarize",
    "href": "lectures/lecture03/lecture03.html#group_by-summarize",
    "title": "Data Wrangling",
    "section": "group_by() & summarize()",
    "text": "group_by() & summarize()\n\nidaho_crashes %>% \n  group_by(IntersectionRelated) %>% \n  summarize(avg_injuries = mean(Number_Of_Injuries))\n\n# A tibble: 2 × 2\n  IntersectionRelated avg_injuries\n  <chr>                      <dbl>\n1 N                          0.478\n2 Y                          0.583"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#summarize-2",
    "href": "lectures/lecture03/lecture03.html#summarize-2",
    "title": "Data Wrangling",
    "section": "summarize()",
    "text": "summarize()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mutate",
    "href": "lectures/lecture03/lecture03.html#mutate",
    "title": "Data Wrangling",
    "section": "mutate()",
    "text": "mutate()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mutate-1",
    "href": "lectures/lecture03/lecture03.html#mutate-1",
    "title": "Data Wrangling",
    "section": "mutate()",
    "text": "mutate()"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#traditional-nested-functions",
    "href": "lectures/lecture03/lecture03.html#traditional-nested-functions",
    "title": "Data Wrangling",
    "section": "Traditional Nested Functions",
    "text": "Traditional Nested Functions\n\nleave_house(get_dressed(get_out_of_bed(wake_up(chris))))"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#filter-to-select-a-subset-of-rows",
    "href": "lectures/lecture03/lecture03.html#filter-to-select-a-subset-of-rows",
    "title": "Data Wrangling",
    "section": "filter() to select a subset of rows",
    "text": "filter() to select a subset of rows\nfor crashes in Canyon county\n\nidaho_crashes %>%\n  filter(County == \"Canyon\") \n\n# A tibble: 35,492 × 12\n   OBJECTID Severity            Mile_Point  Year County Number…¹ Numbe…² Inter…³\n      <dbl> <chr>                    <dbl> <dbl> <chr>     <dbl>   <dbl> <chr>  \n 1    20294 Property Dmg Report      0.004  2005 Canyon        0       0 N      \n 2    21886 Property Dmg Report      5.25   2005 Canyon        0       0 Y      \n 3    26693 Property Dmg Report     NA      2005 Canyon        0       0 Y      \n 4    18673 Property Dmg Report      9.27   2005 Canyon        0       0 N      \n 5    17678 Property Dmg Report     NA      2005 Canyon        0       0 Y      \n 6    17287 B Injury Accident       NA      2005 Canyon        0       1 N      \n 7    26710 Property Dmg Report     NA      2005 Canyon        0       0 N      \n 8    19529 Property Dmg Report     39      2005 Canyon        0       0 N      \n 9    20899 B Injury Accident       50.0    2005 Canyon        0       1 Y      \n10    19655 B Injury Accident       23.5    2005 Canyon        0       1 N      \n# … with 35,482 more rows, 4 more variables: Accident_Date_Time <dttm>,\n#   Hour <int>, Month <ord>, Day <ord>, and abbreviated variable names\n#   ¹​Number_Of_Fatalities, ²​Number_Of_Injuries, ³​IntersectionRelated\n\n\n\ndbl = numerical chr = text data See moderndive 1.4.3 for more info"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#filter-for-many-conditions-at-once",
    "href": "lectures/lecture03/lecture03.html#filter-for-many-conditions-at-once",
    "title": "Data Wrangling",
    "section": "filter() for many conditions at once",
    "text": "filter() for many conditions at once\nfor crashes in Canyon county in 2017\n\nidaho_crashes %>%\n  filter(County == \"Canyon\", Year == 2017) \n\n# A tibble: 3,191 × 12\n   OBJECTID Severity            Mile_Point  Year County Number…¹ Numbe…² Inter…³\n      <dbl> <chr>                    <dbl> <dbl> <chr>     <dbl>   <dbl> <chr>  \n 1   295441 B Injury Accident         4.32  2017 Canyon        0       1 N      \n 2   288513 Fatal Accident           31.1   2017 Canyon        1       1 N      \n 3   293711 Property Dmg Report      31.1   2017 Canyon        0       0 N      \n 4   291456 Property Dmg Report     105.    2017 Canyon        0       0 Y      \n 5   306112 C Injury Accident        31.5   2017 Canyon        0       1 N      \n 6   299918 A Injury Accident        11.2   2017 Canyon        0       1 N      \n 7   295624 C Injury Accident        31.2   2017 Canyon        0       1 N      \n 8   304753 Property Dmg Report      59.3   2017 Canyon        0       0 Y      \n 9   293682 Property Dmg Report       3.03  2017 Canyon        0       0 Y      \n10   292901 Property Dmg Report      28.8   2017 Canyon        0       0 N      \n# … with 3,181 more rows, 4 more variables: Accident_Date_Time <dttm>,\n#   Hour <int>, Month <ord>, Day <ord>, and abbreviated variable names\n#   ¹​Number_Of_Fatalities, ²​Number_Of_Injuries, ³​IntersectionRelated"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#logical-operators-in-r",
    "href": "lectures/lecture03/lecture03.html#logical-operators-in-r",
    "title": "Data Wrangling",
    "section": "Logical operators in R",
    "text": "Logical operators in R\n\n\n\noperator\ndefinition\noperator\ndefinition\n\n\n\n\n<\n\n\n\n\n\n<=\n\n\n\n\n\n>\n\n\n\n\n\n>=\n\n\n\n\n\n==\n\n\n\n\n\n!=\n\n\n\n\n\nx & y"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#select-to-keep-variables",
    "href": "lectures/lecture03/lecture03.html#select-to-keep-variables",
    "title": "Data Wrangling",
    "section": "select() to keep variables",
    "text": "select() to keep variables\n\nidaho_crashes %>%\n  filter(County == \"Canyon\", Year == 2017) %>% \n  select(IntersectionRelated, Number_Of_Injuries)\n\n# A tibble: 3,191 × 2\n   IntersectionRelated Number_Of_Injuries\n   <chr>                            <dbl>\n 1 N                                    1\n 2 N                                    1\n 3 N                                    0\n 4 Y                                    0\n 5 N                                    1\n 6 N                                    1\n 7 N                                    1\n 8 Y                                    0\n 9 Y                                    0\n10 N                                    0\n# … with 3,181 more rows"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#select-to-exclude-variables",
    "href": "lectures/lecture03/lecture03.html#select-to-exclude-variables",
    "title": "Data Wrangling",
    "section": "select() to exclude variables",
    "text": "select() to exclude variables\n\nidaho_crashes %>% \n  select(-OBJECTID)\n\n# A tibble: 299,135 × 11\n   Severity     Mile_…¹  Year County Numbe…² Numbe…³ Inter…⁴ Accident_Date_Time \n   <chr>          <dbl> <dbl> <chr>    <dbl>   <dbl> <chr>   <dttm>             \n 1 Property Dm… 270.     2005 Oneida       0       0 N       2005-01-01 00:01:00\n 2 Property Dm…   0.004  2005 Canyon       0       0 N       2005-01-01 00:01:00\n 3 Property Dm…   5.25   2005 Canyon       0       0 Y       2005-01-01 00:03:00\n 4 Property Dm…   4.6    2005 Twin …       0       0 N       2005-01-01 00:05:00\n 5 C Injury Ac…   1.62   2005 Koote…       0       2 Y       2005-01-01 00:27:00\n 6 Property Dm…  20.5    2005 Ada          0       0 Y       2005-01-01 00:29:00\n 7 Property Dm…  NA      2005 Canyon       0       0 Y       2005-01-01 00:35:00\n 8 Property Dm…  NA      2005 Latah        0       0 N       2005-01-01 00:45:00\n 9 Property Dm…  NA      2005 Koote…       0       0 N       2005-01-01 01:00:00\n10 Property Dm…  NA      2005 Bonne…       0       0 N       2005-01-01 01:25:00\n# … with 299,125 more rows, 3 more variables: Hour <int>, Month <ord>,\n#   Day <ord>, and abbreviated variable names ¹​Mile_Point,\n#   ²​Number_Of_Fatalities, ³​Number_Of_Injuries, ⁴​IntersectionRelated"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#select-a-range-of-variables",
    "href": "lectures/lecture03/lecture03.html#select-a-range-of-variables",
    "title": "Data Wrangling",
    "section": "select() a range of variables",
    "text": "select() a range of variables\n\nidaho_crashes %>% \n  select(Severity:Mile_Point)\n\n# A tibble: 299,135 × 2\n   Severity            Mile_Point\n   <chr>                    <dbl>\n 1 Property Dmg Report    270.   \n 2 Property Dmg Report      0.004\n 3 Property Dmg Report      5.25 \n 4 Property Dmg Report      4.6  \n 5 C Injury Accident        1.62 \n 6 Property Dmg Report     20.5  \n 7 Property Dmg Report     NA    \n 8 Property Dmg Report     NA    \n 9 Property Dmg Report     NA    \n10 Property Dmg Report     NA    \n# … with 299,125 more rows"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mutate-to-add-new-variables",
    "href": "lectures/lecture03/lecture03.html#mutate-to-add-new-variables",
    "title": "Data Wrangling",
    "section": "mutate() to add new variables",
    "text": "mutate() to add new variables"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#mutate-to-add-new-variables-1",
    "href": "lectures/lecture03/lecture03.html#mutate-to-add-new-variables-1",
    "title": "Data Wrangling",
    "section": "mutate() to add new variables",
    "text": "mutate() to add new variables\n\nidaho_crashes %>% \n  mutate(total_inj_fat = Number_Of_Injuries + Number_Of_Fatalities)\n\n# A tibble: 299,135 × 13\n   OBJECTID Severity            Mile_Point  Year County  Numbe…¹ Numbe…² Inter…³\n      <dbl> <chr>                    <dbl> <dbl> <chr>     <dbl>   <dbl> <chr>  \n 1    17633 Property Dmg Report    270.     2005 Oneida        0       0 N      \n 2    20294 Property Dmg Report      0.004  2005 Canyon        0       0 N      \n 3    21886 Property Dmg Report      5.25   2005 Canyon        0       0 Y      \n 4    22038 Property Dmg Report      4.6    2005 Twin F…       0       0 N      \n 5    18025 C Injury Accident        1.62   2005 Kooten…       0       2 Y      \n 6    19661 Property Dmg Report     20.5    2005 Ada           0       0 Y      \n 7    26693 Property Dmg Report     NA      2005 Canyon        0       0 Y      \n 8    18787 Property Dmg Report     NA      2005 Latah         0       0 N      \n 9    19633 Property Dmg Report     NA      2005 Kooten…       0       0 N      \n10    22197 Property Dmg Report     NA      2005 Bonnev…       0       0 N      \n# … with 299,125 more rows, 5 more variables: Accident_Date_Time <dttm>,\n#   Hour <int>, Month <ord>, Day <ord>, total_inj_fat <dbl>, and abbreviated\n#   variable names ¹​Number_Of_Fatalities, ²​Number_Of_Injuries,\n#   ³​IntersectionRelated"
  },
  {
    "objectID": "lectures/lecture03/lecture03.html#save-when-you-mutate",
    "href": "lectures/lecture03/lecture03.html#save-when-you-mutate",
    "title": "Data Wrangling",
    "section": "“Save” when you mutate",
    "text": "“Save” when you mutate\n\nidaho_crashes <- idaho_crashes %>% \n  mutate(total_inj_fat = Number_Of_Injuries + Number_Of_Fatalities)\n\n\nMost often when you define a new variable with mutate you’ll also want to save the resulting data frame, often by writing over the original data frame."
  }
]